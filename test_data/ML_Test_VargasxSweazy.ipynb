{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adef37d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf2113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression # Linear Regression\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier # RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdad2681",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236bf9d6",
   "metadata": {},
   "source": [
    "Step One"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cebd9b",
   "metadata": {},
   "source": [
    "Importing Severe Weather Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4714c9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing test weather data\n",
    "weather_df = pd.read_csv(\"SevereWeatherDetails_appended.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f0334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bce66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns not needed\n",
    "weather_df = weather_df.drop(columns=['INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT', 'DEATHS_INDIRECT',\n",
    "                                     'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'MAGNITUDE', 'TOR_F_SCALE', 'TOR_LENGTH',\n",
    "                                     'TOR_WIDTH', 'BEGIN_LAT', 'BEGIN_LON', 'STATE_FIPS','STATE','CATEGORY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b52934d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying weather df\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58deb6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding together events by groups\n",
    "group_groups = weather_df.groupby(['YEAR','MONTH_NAME', 'EVENT_TYPE'], as_index=False).count()\n",
    "group_groups.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fccdcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename 'EVENT_ID' column as 'Count' and 'YEAR' as 'Year'\n",
    "group_groups = group_groups.rename(columns={'EVENT_ID': 'Count', 'YEAR': 'Year'})\n",
    "group_groups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848e931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Co2 Below This"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d28deaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing test co2 data \n",
    "carbon_df = pd.read_csv(\"co2_byYear.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909d9b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display co2 data\n",
    "carbon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11355442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns for merging purposes\n",
    "carbon_df = carbon_df.rename(columns={\"year\": \"Year\"})\n",
    "carbon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18612999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns not needed\n",
    "carbon_df = carbon_df.drop(columns=['co2_per_unit_energy', 'coal_co2', 'cement_co2', 'flaring_co2', 'gas_co2',\n",
    "                                         'oil_co2', 'other_industry_co2', 'ghg_per_capita', 'methane', 'methane_per_capita',\n",
    "                                         'nitrous_oxide', 'nitrous_oxide_per_capita', 'population', 'gdp', 'primary_energy_consumption',\n",
    "                                         'energy_per_capita', 'energy_per_gdp', 'total_ghg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7624693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show new dataframe\n",
    "carbon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f91813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge attempt one\n",
    "combo_df = group_groups.merge(carbon_df, left_on='Year', right_on='Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d374705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking merge\n",
    "combo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4352c90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the # of yearly events value counts\n",
    "count_counts = combo_df.Count.value_counts()\n",
    "count_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb65d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a2b410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the value counts\n",
    "count_counts.plot.density(xlim=(-50,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e3aa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which values to replace\n",
    "replace_counts = list(count_counts[count_counts < 3].index)\n",
    "\n",
    "# Replace in DataFrame\n",
    "for count in replace_counts:\n",
    "    combo_df.Count = combo_df.Count.replace(count, 0)\n",
    "\n",
    "\n",
    "# Check to make sure binning was successful\n",
    "combo_df.Count.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e64361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combo_df.groupby('Count').filter(lambda x : len(x)>3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e0cd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding machine learning model parameters below here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7baff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = [\"Count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e17178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and testing\n",
    "\n",
    "# Create our features\n",
    "X = pd.get_dummies(combo_df.drop(columns=\"Count\"))\n",
    "\n",
    "# Create our target\n",
    "y = pd.get_dummies(combo_df[\"Count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38d07ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439d6f7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check the balance of our target values\n",
    "y = combo_df['Count']\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74265ebd",
   "metadata": {},
   "source": [
    "# Impliment BalancedRandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eb1f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y)\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5994951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample the training data with the BalancedRandomForestClassifier\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "brfc = BalancedRandomForestClassifier(n_estimators=100, random_state=1)\n",
    "brfc.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cde9986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = brfc.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2f6791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculated the balanced accuracy score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0d73ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the imbalanced classification report\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4805061c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the features sorted in descending order by feature importance\n",
    "sorted(zip(brfc.feature_importances_, X.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e0f4c0",
   "metadata": {},
   "source": [
    "# Easy Ensemble AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b283f007",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y)\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978668bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the EasyEnsembleClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier \n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "eec = EasyEnsembleClassifier(n_estimators=100, random_state=1)\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d603f147",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "eec.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5413d9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eb2d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd533a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the imbalanced classification report\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67914b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the features sorted in descending order by feature importance\n",
    "sorted(zip(eec.feature_importances_, X.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3d9169",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
